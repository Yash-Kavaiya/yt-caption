name: YouTube Screenshot Capture - Dynamic

on:
  push:
    branches:
      - main
      - master
    paths:
      - '**/*.txt'
      - '.github/workflows/youtube-screenshot.yml'
  workflow_dispatch:

jobs:
  find-and-process:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y ffmpeg
          pip install --upgrade pip
          pip install yt-dlp Pillow numpy

      - name: Create processing script
        run: |
          cat > youtube_screenshots.py << 'EOF'
          #!/usr/bin/env python3
          import os, sys, re, subprocess, argparse, tempfile, shutil, json, hashlib, textwrap
          from pathlib import Path
          from PIL import Image
          from datetime import timedelta
          
          def sanitize_filename(filename, max_length=100):
              invalid_chars = '<>:"/\\|?*'
              for char in invalid_chars:
                  filename = filename.replace(char, '')
              filename = filename.strip('. ').replace(' ', '_')
              return filename[:max_length] if len(filename) > max_length else filename
          
          def format_time(seconds):
              return str(timedelta(seconds=int(seconds)))
          
          def get_video_info(url):
              try:
                  cmd = ['yt-dlp', '--dump-json', '--no-playlist', url]
                  result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
                  info = json.loads(result.stdout)
                  return {
                      'title': info.get('title', 'untitled'),
                      'duration': info.get('duration', 0),
                      'uploader': info.get('uploader', 'Unknown'),
                  }
              except Exception as e:
                  print(f"Error getting video info: {e}")
                  return None
          
          def download_video_and_transcript(url, video_path, transcript_path):
              try:
                  format_options = [
                      'bestvideo[height>=1080][ext=mp4]+bestaudio[ext=m4a]/best[height>=1080][ext=mp4]',
                      'bestvideo[height>=720][ext=mp4]+bestaudio[ext=m4a]/best[height>=720][ext=mp4]',
                      'best[ext=mp4]/best'
                  ]
                  cmd = ['yt-dlp', '-f', '/'.join(format_options), '--no-playlist',
                         '--merge-output-format', 'mp4', '-o', video_path,
                         '--write-auto-subs', '--write-subs', '--sub-lang', 'en',
                         '--convert-subs', 'srt', url]
                  subprocess.run(cmd, check=True)
                  video_dir = os.path.dirname(video_path)
                  video_base = os.path.splitext(os.path.basename(video_path))[0]
                  subtitle_patterns = [f"{video_base}.en.srt", f"{video_base}.en.vtt",
                                     f"{video_base}.srt", f"{video_base}.vtt"]
                  transcript_found = False
                  for pattern in subtitle_patterns:
                      potential_file = os.path.join(video_dir, pattern)
                      if os.path.exists(potential_file):
                          convert_srt_to_text(potential_file, transcript_path)
                          transcript_found = True
                          break
                  return True, transcript_found
              except Exception as e:
                  print(f"Error: {e}")
                  return False, False
          
          def convert_srt_to_text(srt_file, text_file):
              try:
                  with open(srt_file, 'r', encoding='utf-8', errors='ignore') as f:
                      lines = f.readlines()
                  transcript_lines = []
                  current_text = []
                  for line in lines:
                      line = line.strip()
                      if line and not line.isdigit() and '-->' not in line:
                          line = re.sub('<[^<]+?>', '', line)
                          current_text.append(line)
                      elif not line and current_text:
                          transcript_lines.append(' '.join(current_text))
                          current_text = []
                  if current_text:
                      transcript_lines.append(' '.join(current_text))
                  with open(text_file, 'w', encoding='utf-8') as f:
                      f.write("VIDEO TRANSCRIPT\n" + "=" * 50 + "\n\n")
                      full_text = ' '.join(transcript_lines)
                      wrapped_text = textwrap.fill(re.sub(r'\s+', ' ', full_text), width=80)
                      f.write(wrapped_text)
                  return True
              except Exception as e:
                  print(f"Error: {e}")
                  return False
          
          def extract_screenshots(video_path, output_dir, interval, title_prefix):
              try:
                  os.makedirs(output_dir, exist_ok=True)
                  cmd = ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                         '-of', 'default=noprint_wrappers=1:nokey=1', video_path]
                  result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                  duration = float(result.stdout.strip())
                  print(f"Duration: {duration:.1f}s, Interval: {interval}s")
                  screenshots = []
                  current_time = 0
                  while current_time <= duration:
                      output_file = os.path.join(output_dir, f"{title_prefix}_{int(current_time):04d}s.png")
                      cmd = ['ffmpeg', '-ss', str(current_time), '-i', video_path,
                             '-vframes', '1', '-y', output_file]
                      subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
                      screenshots.append(output_file)
                      print(f"  [{(current_time/duration)*100:5.1f}%] {format_time(current_time)}")
                      current_time += interval
                  return len(screenshots), screenshots
              except Exception as e:
                  print(f"Error: {e}")
                  return 0, []
          
          def remove_duplicates(files):
              if len(files) <= 1:
                  return 0
              hashes = {}
              to_remove = set()
              for f in files:
                  if not os.path.exists(f):
                      continue
                  try:
                      with open(f, 'rb') as fh:
                          h = hashlib.sha256(fh.read()).hexdigest()
                      if h in hashes:
                          to_remove.add(f)
                      else:
                          hashes[h] = f
                  except:
                      pass
              for f in to_remove:
                  try:
                      os.remove(f)
                  except:
                      pass
              return len(to_remove)
          
          def create_pdf(images_dir, pdf_path, dpi=600):
              try:
                  imgs = sorted(list(Path(images_dir).glob('*.png')) + list(Path(images_dir).glob('*.jpg')))
                  if not imgs:
                      return False
                  pdf_imgs = []
                  for img_path in imgs:
                      try:
                          img = Image.open(img_path)
                          if img.mode != 'RGB':
                              img = img.convert('RGB')
                          if img.width > 3000 or img.height > 3000:
                              img.thumbnail((3000, 3000), Image.Resampling.LANCZOS)
                          pdf_imgs.append(img)
                      except:
                          pass
                  if pdf_imgs:
                      pdf_imgs[0].save(pdf_path, "PDF", resolution=dpi, quality=95,
                                      save_all=True, append_images=pdf_imgs[1:] if len(pdf_imgs) > 1 else [])
                      print(f"PDF: {os.path.getsize(pdf_path)/(1024*1024):.2f} MB")
                      return True
                  return False
              except Exception as e:
                  print(f"Error: {e}")
                  return False
          
          def process_video(url, interval, output_dir='.'):
              info = get_video_info(url)
              if not info:
                  return False
              title = sanitize_filename(info['title'])
              print(f"\n{'='*60}")
              print(f"Video: {info['title']}")
              print(f"Duration: {format_time(info['duration'])}")
              print(f"{'='*60}\n")
              video_dir = Path(output_dir) / title
              images_dir = video_dir / 'images'
              images_dir.mkdir(parents=True, exist_ok=True)
              with tempfile.TemporaryDirectory() as temp_dir:
                  video_path = os.path.join(temp_dir, 'video.mp4')
                  transcript_path = video_dir / f"{title}_transcript.txt"
                  ok, has_transcript = download_video_and_transcript(url, video_path, transcript_path)
                  if not ok:
                      return False
                  count, files = extract_screenshots(video_path, images_dir, interval, title)
                  if count > 0:
                      dups = remove_duplicates(files)
                      print(f"Screenshots: {count}, Duplicates removed: {dups}")
                      pdf_path = video_dir / f"{title}_HD.pdf"
                      create_pdf(images_dir, pdf_path)
                      print(f"âœ… Done: {video_dir.absolute()}")
                      return True
                  return False
          
          if __name__ == "__main__":
              parser = argparse.ArgumentParser()
              parser.add_argument('url')
              parser.add_argument('interval', type=int)
              parser.add_argument('--output-dir', default='.')
              args = parser.parse_args()
              sys.exit(0 if process_video(args.url, args.interval, args.output_dir) else 1)
          EOF
          chmod +x youtube_screenshots.py

      - name: Find and list all .txt files
        run: |
          echo "=== Searching for .txt files ==="
          find . -type f -name "*.txt" ! -path "./output/*" ! -path "./.git/*" | sort
          echo ""
          echo "=== Content of found .txt files ==="
          find . -type f -name "*.txt" ! -path "./output/*" ! -path "./.git/*" | while read file; do
            echo "----------------------------------------"
            echo "FILE: $file"
            echo "----------------------------------------"
            cat "$file"
            echo ""
          done

      - name: Process all videos from all .txt files
        run: |
          mkdir -p output
          
          total_processed=0
          total_failed=0
          
          # Find all .txt files
          find . -type f -name "*.txt" ! -path "./output/*" ! -path "./.git/*" | sort | while read txt_file; do
            echo ""
            echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
            echo "â•‘ Processing: $txt_file"
            echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            
            # Read each line
            while IFS= read -r line || [ -n "$line" ]; do
              # Skip comments and empty lines
              [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]] && continue
              
              # Parse URL and interval
              URL=$(echo "$line" | cut -d',' -f1 | xargs)
              INTERVAL=$(echo "$line" | cut -d',' -f2 | xargs)
              
              # Validate URL
              if [[ ! "$URL" =~ ^https?://.*youtube\.com.*|^https?://.*youtu\.be.* ]]; then
                echo "â­ï¸  Skip invalid: $URL"
                continue
              fi
              
              # Default interval
              [[ -z "$INTERVAL" || "$INTERVAL" == "$URL" ]] && INTERVAL=5
              
              echo ""
              echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
              echo "â”‚ ğŸ¬ URL: $URL"
              echo "â”‚ â±ï¸  Interval: ${INTERVAL}s"
              echo "â”‚ ğŸ“ Source: $txt_file"
              echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
              
              # Process
              if python youtube_screenshots.py "$URL" "$INTERVAL" --output-dir output; then
                echo "âœ… Success"
                ((total_processed++)) || true
              else
                echo "âŒ Failed"
                ((total_failed++)) || true
              fi
              
            done < "$txt_file"
          done
          
          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ SUMMARY"
          echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
          echo "â•‘ âœ… Processed: $total_processed"
          echo "â•‘ âŒ Failed: $total_failed"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: Create index
        run: |
          mkdir -p output
          cat > output/INDEX.md << 'ENDINDEX'
          # Video Processing Index
          
          ENDINDEX
          
          echo "Generated: $(date)" >> output/INDEX.md
          echo "" >> output/INDEX.md
          echo "## Processed Videos" >> output/INDEX.md
          echo "" >> output/INDEX.md
          
          if find output -name "*_HD.pdf" -type f 2>/dev/null | grep -q .; then
            echo "| # | Video Title | PDF | Transcript |" >> output/INDEX.md
            echo "|---|-------------|-----|------------|" >> output/INDEX.md
            counter=1
            for pdf in $(find output -name "*_HD.pdf" -type f | sort); do
              dir=$(dirname "$pdf")
              name=$(basename "$dir")
              pdf_file=$(basename "$pdf")
              transcript="${dir}/${name}_transcript.txt"
              trans_icon="âŒ"
              [ -f "$transcript" ] && trans_icon="âœ…"
              echo "| $counter | $name | [PDF](./$name/$pdf_file) | $trans_icon |" >> output/INDEX.md
              ((counter++))
            done
          else
            echo "No videos processed yet." >> output/INDEX.md
          fi

      - name: Upload PDFs
        uses: actions/upload-artifact@v4
        with:
          name: all-pdfs-${{ github.run_number }}
          path: output/**/*_HD.pdf
          retention-days: 90
          if-no-files-found: warn

      - name: Upload transcripts
        uses: actions/upload-artifact@v4
        with:
          name: all-transcripts-${{ github.run_number }}
          path: output/**/*_transcript.txt
          retention-days: 90
          if-no-files-found: warn

      - name: Commit to repository
        run: |
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config user.name "github-actions[bot]"
          git add output/
          if ! git diff --staged --quiet; then
            git commit -m "YouTube processing batch ${{ github.run_number }} [skip ci]"
            git push || echo "âš ï¸ Push failed"
          fi

      - name: Summary
        run: |
          echo "# âœ… Processing Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          PDF_COUNT=$(find output -name "*_HD.pdf" 2>/dev/null | wc -l)
          TXT_COUNT=$(find output -name "*_transcript.txt" 2>/dev/null | wc -l)
          echo "- PDFs: **$PDF_COUNT**" >> $GITHUB_STEP_SUMMARY
          echo "- Transcripts: **$TXT_COUNT**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check \`output/\` directory or download artifacts below." >> $GITHUB_STEP_SUMMARY
