name: YouTube Screenshot Capture - Fixed

on:
  push:
    branches:
      - main
      - master
    paths:
      - '**/*.txt'
      - '.github/workflows/youtube-screenshot.yml'
  workflow_dispatch:

jobs:
  process-videos:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install and update dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y ffmpeg
          pip install --upgrade pip
          pip install --upgrade yt-dlp Pillow numpy
          
          # Update yt-dlp to latest version
          pip install --upgrade --force-reinstall yt-dlp
          
          echo "yt-dlp version:"
          yt-dlp --version

      - name: Create processing script
        run: |
          cat > youtube_screenshots.py << 'ENDPYTHON'
          #!/usr/bin/env python3
          import os, sys, re, subprocess, argparse, tempfile, shutil, json, hashlib, textwrap, time
          from pathlib import Path
          from PIL import Image
          from datetime import timedelta
          
          def sanitize_filename(filename, max_length=100):
              invalid_chars = '<>:"/\\|?*'
              for char in invalid_chars:
                  filename = filename.replace(char, '')
              filename = filename.strip('. ').replace(' ', '_')
              return filename[:max_length] if len(filename) > max_length else filename
          
          def format_time(seconds):
              return str(timedelta(seconds=int(seconds)))
          
          def get_video_info(url, retries=3):
              for attempt in range(retries):
                  try:
                      # Remove playlist parameters
                      clean_url = re.sub(r'[&?]list=[^&]*', '', url)
                      clean_url = re.sub(r'[&?]index=[^&]*', '', clean_url)
                      
                      cmd = ['yt-dlp', '--dump-json', '--no-playlist', '--no-warnings', clean_url]
                      result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=60)
                      info = json.loads(result.stdout)
                      return {
                          'title': info.get('title', 'untitled'),
                          'duration': info.get('duration', 0),
                          'uploader': info.get('uploader', 'Unknown'),
                      }
                  except subprocess.TimeoutExpired:
                      print(f"Timeout on attempt {attempt+1}/{retries}")
                      if attempt < retries - 1:
                          time.sleep(5)
                  except Exception as e:
                      print(f"Attempt {attempt+1}/{retries} failed: {e}")
                      if attempt < retries - 1:
                          time.sleep(5)
              return None
          
          def download_video_and_transcript(url, video_path, transcript_path, retries=3):
              for attempt in range(retries):
                  try:
                      # Clean URL
                      clean_url = re.sub(r'[&?]list=[^&]*', '', url)
                      clean_url = re.sub(r'[&?]index=[^&]*', '', clean_url)
                      
                      format_options = [
                          'bestvideo[height>=1080][ext=mp4]+bestaudio[ext=m4a]/best[height>=1080][ext=mp4]',
                          'bestvideo[height>=720][ext=mp4]+bestaudio[ext=m4a]/best[height>=720][ext=mp4]',
                          'best[ext=mp4]/best'
                      ]
                      cmd = [
                          'yt-dlp', '-f', '/'.join(format_options), '--no-playlist',
                          '--merge-output-format', 'mp4', '-o', video_path,
                          '--write-auto-subs', '--write-subs', '--sub-lang', 'en',
                          '--convert-subs', 'srt', '--no-warnings',
                          '--extractor-args', 'youtube:player_client=android',
                          clean_url
                      ]
                      subprocess.run(cmd, check=True, timeout=600)
                      
                      # Find transcript
                      video_dir = os.path.dirname(video_path)
                      video_base = os.path.splitext(os.path.basename(video_path))[0]
                      subtitle_patterns = [f"{video_base}.en.srt", f"{video_base}.en.vtt",
                                         f"{video_base}.srt", f"{video_base}.vtt"]
                      transcript_found = False
                      for pattern in subtitle_patterns:
                          potential_file = os.path.join(video_dir, pattern)
                          if os.path.exists(potential_file):
                              convert_srt_to_text(potential_file, transcript_path)
                              transcript_found = True
                              break
                      return True, transcript_found
                  except subprocess.TimeoutExpired:
                      print(f"Download timeout on attempt {attempt+1}/{retries}")
                      if attempt < retries - 1:
                          time.sleep(10)
                  except Exception as e:
                      print(f"Download attempt {attempt+1}/{retries} failed: {e}")
                      if attempt < retries - 1:
                          time.sleep(10)
              return False, False
          
          def convert_srt_to_text(srt_file, text_file):
              try:
                  with open(srt_file, 'r', encoding='utf-8', errors='ignore') as f:
                      lines = f.readlines()
                  transcript_lines = []
                  current_text = []
                  for line in lines:
                      line = line.strip()
                      if line and not line.isdigit() and '-->' not in line:
                          line = re.sub('<[^<]+?>', '', line)
                          current_text.append(line)
                      elif not line and current_text:
                          transcript_lines.append(' '.join(current_text))
                          current_text = []
                  if current_text:
                      transcript_lines.append(' '.join(current_text))
                  with open(text_file, 'w', encoding='utf-8') as f:
                      f.write("VIDEO TRANSCRIPT\n" + "=" * 50 + "\n\n")
                      full_text = ' '.join(transcript_lines)
                      wrapped_text = textwrap.fill(re.sub(r'\s+', ' ', full_text), width=80)
                      f.write(wrapped_text)
                  return True
              except Exception as e:
                  print(f"Transcript error: {e}")
                  return False
          
          def extract_screenshots(video_path, output_dir, interval, title_prefix):
              try:
                  os.makedirs(output_dir, exist_ok=True)
                  cmd = ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                         '-of', 'default=noprint_wrappers=1:nokey=1', video_path]
                  result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                  duration = float(result.stdout.strip())
                  print(f"Duration: {duration:.1f}s, Interval: {interval}s")
                  screenshots = []
                  current_time = 0
                  while current_time <= duration:
                      output_file = os.path.join(output_dir, f"{title_prefix}_{int(current_time):04d}s.png")
                      cmd = ['ffmpeg', '-ss', str(current_time), '-i', video_path,
                             '-vframes', '1', '-y', output_file]
                      subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
                      screenshots.append(output_file)
                      print(f"  [{(current_time/duration)*100:5.1f}%] {format_time(current_time)}")
                      current_time += interval
                  return len(screenshots), screenshots
              except Exception as e:
                  print(f"Screenshot error: {e}")
                  return 0, []
          
          def remove_duplicates(files):
              if len(files) <= 1:
                  return 0
              hashes = {}
              to_remove = set()
              for f in files:
                  if not os.path.exists(f):
                      continue
                  try:
                      with open(f, 'rb') as fh:
                          h = hashlib.sha256(fh.read()).hexdigest()
                      if h in hashes:
                          to_remove.add(f)
                      else:
                          hashes[h] = f
                  except:
                      pass
              for f in to_remove:
                  try:
                      os.remove(f)
                  except:
                      pass
              return len(to_remove)
          
          def create_pdf(images_dir, pdf_path, dpi=600):
              try:
                  imgs = sorted(list(Path(images_dir).glob('*.png')) + list(Path(images_dir).glob('*.jpg')))
                  if not imgs:
                      return False
                  pdf_imgs = []
                  for img_path in imgs:
                      try:
                          img = Image.open(img_path)
                          if img.mode != 'RGB':
                              img = img.convert('RGB')
                          if img.width > 3000 or img.height > 3000:
                              img.thumbnail((3000, 3000), Image.Resampling.LANCZOS)
                          pdf_imgs.append(img)
                      except:
                          pass
                  if pdf_imgs:
                      pdf_imgs[0].save(pdf_path, "PDF", resolution=dpi, quality=95,
                                      save_all=True, append_images=pdf_imgs[1:] if len(pdf_imgs) > 1 else [])
                      print(f"PDF: {os.path.getsize(pdf_path)/(1024*1024):.2f} MB")
                      return True
                  return False
              except Exception as e:
                  print(f"PDF error: {e}")
                  return False
          
          def process_video(url, interval, output_dir='.'):
              print(f"Getting info...")
              info = get_video_info(url)
              if not info:
                  print("Failed to get video info")
                  return False
              title = sanitize_filename(info['title'])
              print(f"Video: {info['title']}")
              print(f"Duration: {format_time(info['duration'])}")
              video_dir = Path(output_dir) / title
              images_dir = video_dir / 'images'
              images_dir.mkdir(parents=True, exist_ok=True)
              with tempfile.TemporaryDirectory() as temp_dir:
                  video_path = os.path.join(temp_dir, 'video.mp4')
                  transcript_path = video_dir / f"{title}_transcript.txt"
                  print("Downloading...")
                  ok, has_transcript = download_video_and_transcript(url, video_path, transcript_path)
                  if not ok:
                      print("Download failed")
                      return False
                  print("Extracting screenshots...")
                  count, files = extract_screenshots(video_path, images_dir, interval, title)
                  if count > 0:
                      dups = remove_duplicates(files)
                      print(f"Screenshots: {count - dups}")
                      pdf_path = video_dir / f"{title}_HD.pdf"
                      create_pdf(images_dir, pdf_path)
                      print(f"âœ… Done!")
                      return True
                  return False
          
          if __name__ == "__main__":
              parser = argparse.ArgumentParser()
              parser.add_argument('url')
              parser.add_argument('interval', type=int)
              parser.add_argument('--output-dir', default='.')
              args = parser.parse_args()
              sys.exit(0 if process_video(args.url, args.interval, args.output_dir) else 1)
          ENDPYTHON
          chmod +x youtube_screenshots.py

      - name: Process all videos
        run: |
          mkdir -p output
          
          success=0
          failed=0
          
          # Process each .txt file (exclude requirements.txt)
          find . -type f -name "*.txt" \
            ! -name "requirements.txt" \
            ! -path "./output/*" \
            ! -path "./.git/*" | sort | while read txt_file; do
            
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "FILE: $txt_file"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            
            while IFS= read -r line || [ -n "$line" ]; do
              # Skip comments and empty
              [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]] && continue
              
              # Parse
              URL=$(echo "$line" | cut -d',' -f1 | xargs)
              INTERVAL=$(echo "$line" | cut -d',' -f2 | xargs)
              
              # Validate
              if [[ ! "$URL" =~ ^https?://.*youtube\. ]] && [[ ! "$URL" =~ ^https?://.*youtu\.be ]]; then
                echo "â­ï¸  Skip: $URL"
                continue
              fi
              
              # Default interval
              [[ -z "$INTERVAL" || "$INTERVAL" == "$URL" ]] && INTERVAL=5
              
              echo ""
              echo "ğŸ¬ $URL"
              echo "â±ï¸  Interval: ${INTERVAL}s"
              
              # Process with timeout
              if timeout 1200 python youtube_screenshots.py "$URL" "$INTERVAL" --output-dir output; then
                echo "âœ… Success"
                ((success++)) || true
              else
                echo "âŒ Failed"
                ((failed++)) || true
              fi
              
              # Sleep between videos to avoid rate limiting
              echo "â¸ï¸  Sleeping 10s..."
              sleep 10
              
            done < "$txt_file"
          done
          
          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "FINAL: âœ… $success | âŒ $failed"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: Create index
        run: |
          mkdir -p output
          echo "# Video Processing Results" > output/INDEX.md
          echo "" >> output/INDEX.md
          echo "Generated: $(date)" >> output/INDEX.md
          echo "" >> output/INDEX.md
          echo "## Videos" >> output/INDEX.md
          echo "" >> output/INDEX.md
          
          if find output -name "*_HD.pdf" -type f 2>/dev/null | grep -q .; then
            echo "| # | Title | PDF | Transcript |" >> output/INDEX.md
            echo "|---|-------|-----|------------|" >> output/INDEX.md
            n=1
            for pdf in $(find output -name "*_HD.pdf" -type f | sort); do
              dir=$(dirname "$pdf")
              name=$(basename "$dir")
              pdffile=$(basename "$pdf")
              trans="${dir}/${name}_transcript.txt"
              ticon="âŒ"
              [ -f "$trans" ] && ticon="âœ…"
              echo "| $n | $name | [PDF](./$name/$pdffile) | $ticon |" >> output/INDEX.md
              ((n++))
            done
          else
            echo "No videos processed." >> output/INDEX.md
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: videos-${{ github.run_number }}
          path: output/
          retention-days: 90

      - name: Commit results
        run: |
          git config user.email "actions@github.com"
          git config user.name "GitHub Actions"
          git add output/
          if ! git diff --staged --quiet; then
            git commit -m "Videos batch ${{ github.run_number }} [skip ci]"
            git push || echo "Push failed"
          fi

      - name: Summary
        run: |
          echo "# Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          count=$(find output -name "*_HD.pdf" 2>/dev/null | wc -l)
          echo "PDFs generated: **$count**" >> $GITHUB_STEP_SUMMARY
