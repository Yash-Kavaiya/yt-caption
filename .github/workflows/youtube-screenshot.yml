name: YouTube Screenshot Capture - All TXT Files

on:
  push:
    branches:
      - main
      - master
    paths:
      - '**/*.txt'
      - '.github/workflows/youtube-screenshot.yml'
  workflow_dispatch:
    inputs:
      video_url:
        description: 'YouTube video URL (optional - for single video)'
        required: false
        type: string
      interval:
        description: 'Screenshot interval in seconds'
        required: false
        default: '5'
        type: string

jobs:
  process-videos:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y ffmpeg
          echo "‚úì FFmpeg installed"

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install yt-dlp Pillow numpy
          echo "‚úì Python dependencies installed"

      - name: Create processing script
        run: |
          cat > youtube_screenshots.py << 'EOF'
          #!/usr/bin/env python3
          """Enhanced YouTube Video Screenshot Capture Tool"""
          
          import os
          import sys
          import re
          import subprocess
          import argparse
          import tempfile
          import shutil
          from pathlib import Path
          import json
          import hashlib
          from PIL import Image
          from datetime import timedelta
          import textwrap
          
          def sanitize_filename(filename, max_length=100):
              invalid_chars = '<>:"/\\|?*'
              for char in invalid_chars:
                  filename = filename.replace(char, '')
              filename = filename.strip('. ')
              filename = filename.replace(' ', '_')
              if len(filename) > max_length:
                  filename = filename[:max_length]
              return filename
          
          def format_time(seconds):
              return str(timedelta(seconds=int(seconds)))
          
          def get_video_info(url):
              try:
                  cmd = ['yt-dlp', '--dump-json', '--no-playlist', url]
                  result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
                  info = json.loads(result.stdout)
                  subtitles_available = bool(info.get('subtitles', {})) or bool(info.get('automatic_captions', {}))
                  return {
                      'title': info.get('title', 'untitled'),
                      'duration': info.get('duration', 0),
                      'uploader': info.get('uploader', 'Unknown'),
                      'view_count': info.get('view_count', 0),
                      'subtitles_available': subtitles_available
                  }
              except Exception as e:
                  print(f"Error getting video info: {e}")
                  return None
          
          def download_video_and_transcript(url, video_path, transcript_path, force_hd=True):
              try:
                  format_options = [
                      'bestvideo[height>=1080][ext=mp4]+bestaudio[ext=m4a]/best[height>=1080][ext=mp4]',
                      'bestvideo[height>=720][ext=mp4]+bestaudio[ext=m4a]/best[height>=720][ext=mp4]',
                      'best[ext=mp4]/best'
                  ]
                  cmd = [
                      'yt-dlp', '-f', '/'.join(format_options), '--no-playlist',
                      '--merge-output-format', 'mp4', '-o', video_path,
                      '--write-auto-subs', '--write-subs', '--sub-lang', 'en',
                      '--convert-subs', 'srt', url
                  ]
                  print("Downloading video...")
                  subprocess.run(cmd, check=True)
                  video_dir = os.path.dirname(video_path)
                  video_base = os.path.splitext(os.path.basename(video_path))[0]
                  subtitle_patterns = [
                      f"{video_base}.en.srt", f"{video_base}.en.vtt",
                      f"{video_base}.srt", f"{video_base}.vtt"
                  ]
                  transcript_found = False
                  for pattern in subtitle_patterns:
                      potential_file = os.path.join(video_dir, pattern)
                      if os.path.exists(potential_file):
                          convert_srt_to_text(potential_file, transcript_path)
                          transcript_found = True
                          break
                  return True, transcript_found
              except Exception as e:
                  print(f"Error downloading video: {e}")
                  return False, False
          
          def convert_srt_to_text(srt_file, text_file):
              try:
                  with open(srt_file, 'r', encoding='utf-8', errors='ignore') as f:
                      lines = f.readlines()
                  transcript_lines = []
                  current_text = []
                  for line in lines:
                      line = line.strip()
                      if line and not line.isdigit() and '-->' not in line:
                          line = re.sub('<[^<]+?>', '', line)
                          current_text.append(line)
                      elif not line and current_text:
                          transcript_lines.append(' '.join(current_text))
                          current_text = []
                  if current_text:
                      transcript_lines.append(' '.join(current_text))
                  with open(text_file, 'w', encoding='utf-8') as f:
                      f.write("VIDEO TRANSCRIPT\n")
                      f.write("=" * 50 + "\n\n")
                      full_text = ' '.join(transcript_lines)
                      full_text = re.sub(r'\s+', ' ', full_text)
                      wrapped_text = textwrap.fill(full_text, width=80)
                      f.write(wrapped_text)
                  return True
              except Exception as e:
                  print(f"Error converting transcript: {e}")
                  return False
          
          def extract_high_quality_screenshots(video_path, output_dir, interval, title_prefix, quality='highest'):
              try:
                  os.makedirs(output_dir, exist_ok=True)
                  cmd = [
                      'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                      '-of', 'default=noprint_wrappers=1:nokey=1', video_path
                  ]
                  result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                  duration = float(result.stdout.strip())
                  print(f"Video duration: {duration:.1f} seconds")
                  print(f"Extracting screenshots every {interval} seconds...")
                  screenshots_taken = 0
                  current_time = 0
                  screenshot_files = []
                  while current_time <= duration:
                      time_str = f"{int(current_time):04d}s"
                      if quality == 'highest':
                          output_file = os.path.join(output_dir, f"{title_prefix}_{time_str}.png")
                          cmd = ['ffmpeg', '-ss', str(current_time), '-i', video_path,
                                 '-vframes', '1', '-vf', 'scale=iw:ih', '-y', output_file]
                      else:
                          output_file = os.path.join(output_dir, f"{title_prefix}_{time_str}.jpg")
                          cmd = ['ffmpeg', '-ss', str(current_time), '-i', video_path,
                                 '-vframes', '1', '-q:v', '1', '-y', output_file]
                      subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
                      screenshots_taken += 1
                      screenshot_files.append(output_file)
                      progress = (current_time / duration) * 100
                      print(f"  [{progress:5.1f}%] Screenshot at {format_time(current_time)}")
                      current_time += interval
                  return screenshots_taken, screenshot_files
              except Exception as e:
                  print(f"Error extracting screenshots: {e}")
                  return 0, []
          
          def get_image_hash(image_path):
              try:
                  with open(image_path, 'rb') as f:
                      return hashlib.sha256(f.read()).hexdigest()
              except Exception:
                  return None
          
          def remove_duplicate_screenshots(screenshot_files):
              if len(screenshot_files) <= 1:
                  return 0
              print("\nRemoving duplicate screenshots...")
              duplicates_removed = 0
              files_to_remove = set()
              processed_hashes = {}
              for current_file in screenshot_files:
                  if current_file in files_to_remove or not os.path.exists(current_file):
                      continue
                  current_hash = get_image_hash(current_file)
                  if not current_hash:
                      continue
                  if current_hash in processed_hashes:
                      files_to_remove.add(current_file)
                  else:
                      processed_hashes[current_hash] = current_file
              for file_path in files_to_remove:
                  try:
                      os.remove(file_path)
                      duplicates_removed += 1
                  except Exception:
                      pass
              return duplicates_removed
          
          def create_hd_pdf(images_dir, pdf_path, dpi=600):
              try:
                  print(f"\nCreating PDF (DPI: {dpi})...")
                  image_files = sorted(list(Path(images_dir).glob('*.jpg')) + list(Path(images_dir).glob('*.png')))
                  if not image_files:
                      return False
                  pdf_images = []
                  for img_path in image_files:
                      try:
                          img = Image.open(img_path)
                          if img.mode != 'RGB':
                              img = img.convert('RGB')
                          max_dimension = 3000
                          if img.width > max_dimension or img.height > max_dimension:
                              img.thumbnail((max_dimension, max_dimension), Image.Resampling.LANCZOS)
                          pdf_images.append(img)
                      except Exception:
                          pass
                  if pdf_images:
                      pdf_images[0].save(
                          pdf_path, "PDF", resolution=dpi, quality=95, optimize=True,
                          save_all=True, append_images=pdf_images[1:] if len(pdf_images) > 1 else []
                      )
                      file_size = os.path.getsize(pdf_path) / (1024 * 1024)
                      print(f"  ‚úì PDF created: {file_size:.2f} MB")
                      return True
                  return False
              except Exception as e:
                  print(f"Error creating PDF: {e}")
                  return False
          
          def process_video(url, interval, output_dir='.', quality='highest',
                           pdf_dpi=600, keep_video=False, no_transcript=False, no_pdf=False):
              print(f"Fetching video information...")
              video_info = get_video_info(url)
              if not video_info:
                  return False
              safe_title = sanitize_filename(video_info['title'])
              print(f"\n{'='*60}")
              print(f"Video: {video_info['title']}")
              print(f"Duration: {format_time(video_info['duration'])}")
              print(f"Uploader: {video_info['uploader']}")
              print(f"{'='*60}\n")
              base_dir = Path(output_dir)
              video_dir = base_dir / safe_title
              images_dir = video_dir / 'images'
              images_dir.mkdir(parents=True, exist_ok=True)
              with tempfile.TemporaryDirectory() as temp_dir:
                  video_path = os.path.join(temp_dir, 'video.mp4')
                  transcript_path = video_dir / f"{safe_title}_transcript.txt"
                  video_success, transcript_success = download_video_and_transcript(
                      url, video_path, transcript_path if not no_transcript else None
                  )
                  if not video_success:
                      print("Error: Failed to download video")
                      return False
                  print(f"\n‚úì Video downloaded successfully!")
                  screenshot_count, screenshot_files = extract_high_quality_screenshots(
                      video_path, images_dir, interval, safe_title, quality
                  )
                  if screenshot_count > 0:
                      print(f"\n‚úì Extracted {screenshot_count} screenshots")
                      duplicates = remove_duplicate_screenshots(screenshot_files)
                      if duplicates > 0:
                          print(f"‚úì Removed {duplicates} duplicates")
                          print(f"  Final: {screenshot_count - duplicates} unique screenshots")
                      if not no_pdf:
                          pdf_path = video_dir / f"{safe_title}_HD.pdf"
                          create_hd_pdf(images_dir, pdf_path, pdf_dpi)
                      if keep_video:
                          final_video_path = video_dir / f"{safe_title}.mp4"
                          shutil.copy2(video_path, final_video_path)
                      print(f"\n{'='*60}")
                      print(f"‚úÖ COMPLETED SUCCESSFULLY!")
                      print(f"{'='*60}")
                      print(f"üìÅ Output: {video_dir.absolute()}")
                      print(f"üñºÔ∏è  Screenshots: {len(screenshot_files) - duplicates}")
                      if not no_pdf:
                          print(f"üìÑ PDF: {pdf_path.name}")
                      if transcript_success:
                          print(f"üìù Transcript: {transcript_path.name}")
                      print(f"{'='*60}\n")
                      return True
                  else:
                      print("Error: No screenshots extracted")
                      return False
          
          if __name__ == "__main__":
              parser = argparse.ArgumentParser(description='YouTube Screenshot Tool')
              parser.add_argument('url', help='YouTube video URL')
              parser.add_argument('interval', type=int, help='Interval in seconds')
              parser.add_argument('--output-dir', default='.', help='Output directory')
              parser.add_argument('--quality', choices=['high', 'highest'], default='highest')
              parser.add_argument('--pdf-dpi', type=int, default=600)
              parser.add_argument('--keep-video', action='store_true')
              parser.add_argument('--no-transcript', action='store_true')
              parser.add_argument('--no-pdf', action='store_true')
              args = parser.parse_args()
              success = process_video(
                  args.url, args.interval, args.output_dir,
                  args.quality, args.pdf_dpi, args.keep_video,
                  args.no_transcript, args.no_pdf
              )
              sys.exit(0 if success else 1)
          EOF
          
          chmod +x youtube_screenshots.py
          echo "‚úì Processing script created"

      - name: Find all .txt files with video URLs
        id: find_files
        run: |
          echo "Searching for .txt files with YouTube URLs..."
          find . -type f -name "*.txt" ! -path "./output/*" ! -path "./.git/*" ! -path "./.*" > found_files.txt
          echo "Found .txt files:"
          cat found_files.txt
          FILE_COUNT=$(wc -l < found_files.txt)
          echo "total_files=$FILE_COUNT" >> $GITHUB_OUTPUT
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "‚ö†Ô∏è  No .txt files found"
          else
            echo "‚úì Found $FILE_COUNT .txt file(s)"
          fi

      - name: Process all .txt files with video URLs
        if: steps.find_files.outputs.total_files > 0
        run: |
          mkdir -p output
          echo "========================================="
          echo "Processing all .txt files"
          echo "========================================="
          while IFS= read -r txt_file; do
            echo ""
            echo "üìÑ Processing file: $txt_file"
            echo "-----------------------------------------"
            if [ ! -s "$txt_file" ]; then
              echo "‚è≠Ô∏è  Skipping empty file"
              continue
            fi
            while IFS= read -r line || [ -n "$line" ]; do
              if [[ -z "$line" ]] || [[ "$line" =~ ^[[:space:]]*# ]]; then
                continue
              fi
              URL=$(echo "$line" | cut -d',' -f1 | xargs)
              INTERVAL=$(echo "$line" | cut -d',' -f2 | xargs)
              if [[ ! "$URL" =~ ^https?:// ]]; then
                echo "‚è≠Ô∏è  Skipping invalid URL: $URL"
                continue
              fi
              if [ -z "$INTERVAL" ] || [ "$INTERVAL" = "$URL" ]; then
                INTERVAL=5
              fi
              echo ""
              echo "üé¨ Processing video:"
              echo "   URL: $URL"
              echo "   Interval: $INTERVAL seconds"
              echo "   Source: $txt_file"
              echo ""
              python youtube_screenshots.py "$URL" "$INTERVAL" --output-dir output --quality highest --pdf-dpi 600 || echo "‚ö†Ô∏è  Failed to process $URL"
            done < "$txt_file"
          done < found_files.txt
          echo ""
          echo "========================================="
          echo "‚úÖ All .txt files processed"
          echo "========================================="

      - name: Process single video (manual trigger)
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.video_url != ''
        run: |
          mkdir -p output
          python youtube_screenshots.py "${{ github.event.inputs.video_url }}" "${{ github.event.inputs.interval }}" --output-dir output --quality highest --pdf-dpi 600

      - name: Create summary and index
        run: |
          mkdir -p output
          CURRENT_DATE=$(date)
          WORKFLOW_RUN="${{ github.run_number }}"
          COMMIT_SHA="${{ github.sha }}"
          
          cat > output/INDEX.md << 'ENDOFINDEX'
          # YouTube Screenshot Processing - Index
          
          ENDOFINDEX
          
          echo "**Generated:** $CURRENT_DATE" >> output/INDEX.md
          echo "**Workflow Run:** $WORKFLOW_RUN" >> output/INDEX.md
          echo "**Commit:** $COMMIT_SHA" >> output/INDEX.md
          echo "" >> output/INDEX.md
          echo "---" >> output/INDEX.md
          echo "" >> output/INDEX.md
          echo "## Processed Videos" >> output/INDEX.md
          echo "" >> output/INDEX.md
          
          if find output -name "*_HD.pdf" -type f | grep -q .; then
            echo "| Video | PDF | Transcript | Screenshots |" >> output/INDEX.md
            echo "|-------|-----|------------|-------------|" >> output/INDEX.md
            for pdf in $(find output -name "*_HD.pdf" -type f | sort); do
              dir=$(dirname "$pdf")
              basename=$(basename "$dir")
              pdf_name=$(basename "$pdf")
              transcript="${dir}/${basename}_transcript.txt"
              screenshot_count=$(find "${dir}/images" -name "*.png" -o -name "*.jpg" 2>/dev/null | wc -l)
              transcript_link="‚ùå"
              if [ -f "$transcript" ]; then
                transcript_link="üìù Yes"
              fi
              echo "| $basename | [Download](./$basename/$pdf_name) | $transcript_link | $screenshot_count |" >> output/INDEX.md
            done
          else
            echo "*No videos processed yet.*" >> output/INDEX.md
          fi
          
          echo "" >> output/INDEX.md
          echo "---" >> output/INDEX.md
          echo "" >> output/INDEX.md
          echo "## How to Add More Videos" >> output/INDEX.md
          echo "" >> output/INDEX.md
          echo "1. Create or edit any .txt file" >> output/INDEX.md
          echo "2. Add YouTube URLs (one per line): \`https://youtu.be/VIDEO_ID,5\`" >> output/INDEX.md
          echo "3. Commit and push - automatic processing!" >> output/INDEX.md
          
          echo "‚úì Index created"

      - name: Upload PDFs as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pdfs-${{ github.run_number }}
          path: output/**/*_HD.pdf
          retention-days: 90
          if-no-files-found: warn

      - name: Upload transcripts as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: transcripts-${{ github.run_number }}
          path: output/**/*_transcript.txt
          retention-days: 90
          if-no-files-found: warn

      - name: Upload complete output
        uses: actions/upload-artifact@v4
        with:
          name: complete-output-${{ github.run_number }}
          path: output/
          retention-days: 90
          if-no-files-found: warn

      - name: Commit results to repository
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add output/ || true
          if git diff --staged --quiet; then
            echo "No new files to commit"
          else
            FILES_ADDED=$(git diff --staged --name-only | wc -l)
            git commit -m "Auto-generated: YouTube screenshots and PDFs - $FILES_ADDED files [skip ci]"
            echo "Committed $FILES_ADDED files"
            git push || echo "Push failed - check repository permissions"
          fi

      - name: Create job summary
        run: |
          echo "# YouTube Screenshot Processing Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          PDF_COUNT=$(find output -name "*_HD.pdf" -type f 2>/dev/null | wc -l)
          TXT_COUNT=$(find output -name "*_transcript.txt" -type f 2>/dev/null | wc -l)
          IMG_COUNT=$(find output -type f \( -name "*.png" -o -name "*.jpg" \) 2>/dev/null | wc -l)
          echo "- PDFs generated: $PDF_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- Transcripts: $TXT_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- Screenshots: $IMG_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Files are available in:" >> $GITHUB_STEP_SUMMARY
          echo "1. Repository output/ directory" >> $GITHUB_STEP_SUMMARY
          echo "2. Artifacts section (scroll down)" >> $GITHUB_STEP_SUMMARY
